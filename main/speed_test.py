import requests
import time
import os
import urllib3
from typing import List, Dict, Optional

# å±è”½SSLéªŒè¯è­¦å‘Šï¼ˆé€‚é…éƒ¨åˆ†ç§æœ‰æµåª’ä½“æœåŠ¡å™¨ï¼‰
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# å¯é€‰ï¼šå¯¼å…¥tqdmå®ç°è¿›åº¦æ¡ï¼ˆæœªå®‰è£…ä¸å½±å“æ ¸å¿ƒåŠŸèƒ½ï¼‰
try:
    from tqdm import tqdm
except ImportError:
    tqdm = lambda x, desc=None: x  # å…¼å®¹æ— tqdmçš„ç¯å¢ƒ

# ===================== æ ¸å¿ƒé…ç½®é¡¹ï¼ˆæŒ‰éœ€è°ƒæ•´ï¼‰ =====================
# æµ‹é€Ÿå‚æ•°
DOWNLOAD_TEST_SIZE = 1024 * 1024 * 2  # 2MBï¼Œå…¼é¡¾æµ‹é€Ÿç²¾å‡†åº¦å’Œè€—æ—¶
TIMEOUT = 20  # ç½‘ç»œè¯·æ±‚è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰ï¼Œç½‘ç»œå·®å¯é€‚å½“è°ƒå¤§
USER_AGENT = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"

# ç»“æœä¿å­˜é…ç½®
SAVE_RESULT = True
RESULT_SAVE_PATH = "iptv_url_speed_test_result.txt"

# æµåª’ä½“åè®®å‰ç¼€ï¼ˆæ”¯æŒçš„é“¾æ¥æ ¼å¼ï¼Œå¯æ‰©å±•ï¼‰
SUPPORTED_PROTOCOLS = [
    "http://",
    "https://",
    "rtmp://",
    "rtsp://",
    "mms://",
    "hls://"
]

# ===================== å·¥å…·å‡½æ•°ï¼šä»æ–‡æœ¬ä¸­æå–æ‰€æœ‰æœ‰æ•ˆæµåª’ä½“é“¾æ¥ =====================
def extract_all_streaming_links(text_content: str) -> List[str]:
    """
    ä»ä»»æ„æ–‡æœ¬å†…å®¹ä¸­ï¼Œæå–æ‰€æœ‰æ”¯æŒçš„æµåª’ä½“é“¾æ¥ï¼ˆæ ¸å¿ƒï¼šä¸é™åˆ¶æ ¼å¼ï¼ŒåªåŒ¹é…åè®®å‰ç¼€ï¼‰
    :param text_content: ç½‘ç»œæ–‡ä»¶ä¸‹è½½çš„åŸå§‹æ–‡æœ¬å†…å®¹
    :return: å»é‡åçš„æœ‰æ•ˆæµåª’ä½“é“¾æ¥åˆ—è¡¨
    """
    if not text_content:
        return []
    
    streaming_links = []
    text_lines = text_content.split("\n")

    # éå†æ¯ä¸€è¡Œï¼Œæå–æ‰€æœ‰ç¬¦åˆåè®®å‰ç¼€çš„é“¾æ¥
    for line in text_lines:
        line = line.strip()
        if not line:
            continue
        
        # éå†æ‰€æœ‰æ”¯æŒçš„åè®®ï¼Œæå–å®Œæ•´é“¾æ¥
        for proto in SUPPORTED_PROTOCOLS:
            proto_length = len(proto)
            start_index = 0
            
            # ä¸€è¡Œä¸­å¯èƒ½åŒ…å«å¤šä¸ªé“¾æ¥ï¼Œå¾ªç¯æå–
            while True:
                # æŸ¥æ‰¾å½“å‰åè®®åœ¨è¯¥è¡Œçš„èµ·å§‹ä½ç½®
                link_start = line.find(proto, start_index)
                if link_start == -1:
                    break  # æ— æ›´å¤šè¯¥åè®®é“¾æ¥ï¼Œåˆ‡æ¢ä¸‹ä¸€ä¸ªåè®®
                
                # æå–é“¾æ¥ç»“æŸä½ç½®ï¼ˆé‡åˆ°åˆ†éš”ç¬¦å³åœæ­¢ï¼‰
                link_end = link_start + proto_length
                separators = [" ", ",", "\"", "'", "\t", "#", ")", "]", ";", "<", ">"]
                while link_end < len(line):
                    if line[link_end] in separators:
                        break
                    link_end += 1
                
                # æå–å¹¶éªŒè¯é“¾æ¥ï¼ˆè‡³å°‘åŒ…å«åè®®+åŸŸåï¼Œé¿å…æ— æ•ˆçŸ­é“¾æ¥ï¼‰
                extracted_link = line[link_start:link_end].strip()
                if len(extracted_link) > proto_length + 3:  # è‡³å°‘ proto://xxx æ ¼å¼
                    streaming_links.append(extracted_link)
                
                # æ›´æ–°èµ·å§‹ä½ç½®ï¼Œç»§ç»­æŸ¥æ‰¾è¯¥è¡Œå‰©ä½™çš„åŒåè®®é“¾æ¥
                start_index = link_end
    
    # å»é‡ï¼ˆä¿æŒé“¾æ¥æå–é¡ºåºï¼Œé¿å…é‡å¤æµ‹é€Ÿï¼‰
    unique_links = list(dict.fromkeys(streaming_links))
    return unique_links

# ===================== å·¥å…·å‡½æ•°ï¼šä¸‹è½½ç½‘ç»œURLæ–‡ä»¶å¹¶æå–æµåª’ä½“é“¾æ¥ =====================
def get_streaming_links_from_network_url(network_url: str) -> List[str]:
    """
    ä¸‹è½½æŒ‡å®šç½‘ç»œURLçš„æ–‡ä»¶å†…å®¹ï¼Œæå–å…¶ä¸­æ‰€æœ‰æœ‰æ•ˆæµåª’ä½“é“¾æ¥
    :param network_url: ç½‘ç»œæ–‡ä»¶URLï¼ˆå¦‚GitHub RAWã€å…¬å…±IPTVåˆ—è¡¨URLç­‰ï¼‰
    :return: å¾…æµ‹é€Ÿçš„æµåª’ä½“é“¾æ¥åˆ—è¡¨
    """
    print(f"ğŸ“¥  å¼€å§‹ä¸‹è½½å¹¶è§£æç½‘ç»œæ–‡ä»¶ï¼š{network_url}")
    headers = {"User-Agent": USER_AGENT}
    
    try:
        # ä¸‹è½½ç½‘ç»œæ–‡ä»¶å†…å®¹
        response = requests.get(
            network_url,
            headers=headers,
            timeout=TIMEOUT,
            verify=False
        )
        response.raise_for_status()  # æ•è·HTTPé”™è¯¯ï¼ˆ404/500ç­‰ï¼‰
        print(f"âœ…  ç½‘ç»œæ–‡ä»¶ä¸‹è½½æˆåŠŸï¼Œå¼€å§‹æå–æµåª’ä½“é“¾æ¥...")
        
        # æå–æ‰€æœ‰æœ‰æ•ˆæµåª’ä½“é“¾æ¥
        streaming_links = extract_all_streaming_links(response.text)
        print(f"ğŸ‰  é“¾æ¥æå–å®Œæˆï¼Œå…±è·å– {len(streaming_links)} ä¸ªæœ‰æ•ˆæµåª’ä½“é“¾æ¥\n")
        return streaming_links
    
    except requests.exceptions.Timeout:
        print(f"âŒ  ä¸‹è½½è¶…æ—¶ï¼š{network_url}ï¼ˆè¶…æ—¶æ—¶é—´ï¼š{TIMEOUT}ç§’ï¼‰")
    except requests.exceptions.HTTPError as e:
        print(f"âŒ  HTTPé”™è¯¯ï¼š{network_url}ï¼Œé”™è¯¯ç ï¼š{e.response.status_code}")
    except Exception as e:
        print(f"âŒ  è§£æå¤±è´¥ï¼š{network_url}ï¼Œé”™è¯¯ä¿¡æ¯ï¼š{str(e)}")
    
    return []

# ===================== æ ¸å¿ƒå‡½æ•°ï¼šå•ä¸ªæµåª’ä½“é“¾æ¥æµ‹é€Ÿ =====================
def test_single_stream_link_speed(link: str) -> Optional[Dict]:
    """
    æµ‹è¯•å•ä¸ªæµåª’ä½“é“¾æ¥çš„è¿é€šæ€§ã€å»¶è¿Ÿå’Œä¸‹è½½é€Ÿåº¦
    :param link: æœ‰æ•ˆæµåª’ä½“é“¾æ¥
    :return: æµ‹é€Ÿç»“æœå­—å…¸ï¼ˆå¤±è´¥è¿”å›Noneï¼‰
    """
    result = {
        "link": link,
        "is_available": False,
        "response_delay_ms": 0.0,
        "download_speed_mbps": 0.0,
        "error_msg": ""
    }

    headers = {"User-Agent": USER_AGENT}

    try:
        # 1. æµ‹è¯•å“åº”å»¶è¿Ÿï¼ˆå»ºç«‹è¿æ¥+è·å–å“åº”å¤´è€—æ—¶ï¼‰
        start_time = time.time()
        response = requests.get(
            link,
            headers=headers,
            timeout=TIMEOUT,
            stream=True,
            verify=False
        )
        response.raise_for_status()
        end_time = time.time()

        # è®¡ç®—å»¶è¿Ÿï¼ˆæ¯«ç§’ï¼‰
        response_delay = (end_time - start_time) * 1000
        result["response_delay_ms"] = round(response_delay, 2)
        result["is_available"] = True

        # 2. æµ‹è¯•ä¸‹è½½é€Ÿåº¦ï¼ˆæ‹‰å–æŒ‡å®šå¤§å°çš„æµåª’ä½“æ•°æ®ï¼‰
        downloaded_size = 0
        download_start = time.time()
        chunk_size = 4096  # è°ƒå¤§åˆ†ç‰‡å¤§å°ï¼Œæå‡æµåª’ä½“æ‹‰å–æ•ˆç‡

        for chunk in response.iter_content(chunk_size=chunk_size):
            if chunk and len(chunk) > 0:  # è¿‡æ»¤ç©ºåˆ†ç‰‡ï¼Œé¿å…æ— æ•ˆæ•°æ®ç»Ÿè®¡
                downloaded_size += len(chunk)
                # è¾¾åˆ°æµ‹è¯•å¤§å°æˆ–è¶…æ—¶ï¼Œç»ˆæ­¢æ‹‰å–
                if (downloaded_size >= DOWNLOAD_TEST_SIZE) or (time.time() - download_start) > TIMEOUT:
                    break

        download_end = time.time()
        download_duration = download_end - download_start

        # è®¡ç®—ä¸‹è½½é€Ÿåº¦ï¼ˆMbpsï¼Œé¿å…é™¤ä»¥é›¶é”™è¯¯ï¼‰
        if download_duration > 0.001 and downloaded_size > 0:
            downloaded_mb = downloaded_size / (1024 * 1024)
            download_speed_mbps = (downloaded_mb * 8) / download_duration
            result["download_speed_mbps"] = round(download_speed_mbps, 2)
        else:
            result["download_speed_mbps"] = 0.0
            result["error_msg"] = "æœªè·å–åˆ°æœ‰æ•ˆæµåª’ä½“æ•°æ®ï¼ˆæœåŠ¡å™¨é™åˆ¶æˆ–éç›´æ’­æµï¼‰"

        return result

    except requests.exceptions.Timeout:
        result["error_msg"] = "è¯·æ±‚è¶…æ—¶ï¼ˆé“¾æ¥å¤±æ•ˆæˆ–ç½‘ç»œè¾ƒå·®ï¼‰"
    except requests.exceptions.HTTPError as e:
        result["error_msg"] = f"HTTPé”™è¯¯ï¼š{str(e)}"
    except Exception as e:
        result["error_msg"] = f"æœªçŸ¥é”™è¯¯ï¼š{str(e)}"

    return result

# ===================== æ ¸å¿ƒå‡½æ•°ï¼šæ‰¹é‡æµåª’ä½“é“¾æ¥æµ‹é€Ÿ =====================
def batch_test_stream_links(network_url_list: List[str]) -> List[Dict]:
    """
    æ‰¹é‡å¤„ç†ç½‘ç»œURLï¼Œæå–æµåª’ä½“é“¾æ¥å¹¶å®Œæˆæµ‹é€Ÿï¼Œè¿”å›æ’åºåçš„ç»“æœ
    :param network_url_list: ç½‘ç»œæ–‡ä»¶URLåˆ—è¡¨
    :return: æŒ‰ä¸‹è½½é€Ÿåº¦é™åºæ’åºçš„æµ‹é€Ÿç»“æœåˆ—è¡¨
    """
    # ç¬¬ä¸€æ­¥ï¼šæå–æ‰€æœ‰ç½‘ç»œURLä¸­çš„æµåª’ä½“é“¾æ¥
    all_stream_links = []
    for url in network_url_list:
        links = get_streaming_links_from_network_url(url)
        all_stream_links.extend(links)
    
    # å»é‡ï¼Œé¿å…é‡å¤æµ‹é€Ÿ
    unique_stream_links = list(dict.fromkeys(all_stream_links))
    if not unique_stream_links:
        print("âŒ  æ— æœ‰æ•ˆå¾…æµ‹é€Ÿæµåª’ä½“é“¾æ¥ï¼Œç»ˆæ­¢æµ‹é€Ÿæµç¨‹")
        return []

    # ç¬¬äºŒæ­¥ï¼šæ‰¹é‡æµ‹é€Ÿ
    print(f"ğŸš€  å¼€å§‹æ‰¹é‡æµ‹é€Ÿï¼ˆå…± {len(unique_stream_links)} ä¸ªé“¾æ¥ï¼Œè€å¿ƒç­‰å¾…...ï¼‰\n")
    speed_results = []

    for link in tqdm(unique_stream_links, desc="æµ‹é€Ÿè¿›åº¦"):
        test_result = test_single_stream_link_speed(link)
        if test_result:
            speed_results.append(test_result)

    # ç¬¬ä¸‰æ­¥ï¼šæ’åºï¼ˆå¯ç”¨çŠ¶æ€â†’ä¸‹è½½é€Ÿåº¦é™åºâ†’å»¶è¿Ÿå‡åºï¼‰
    speed_results.sort(
        key=lambda x: (x["is_available"], x["download_speed_mbps"], -x["response_delay_ms"]),
        reverse=True
    )

    return speed_results

# ===================== å·¥å…·å‡½æ•°ï¼šæ‰“å°å¹¶ä¿å­˜æµ‹é€Ÿç»“æœ =====================
def print_and_save_speed_results(speed_results: List[Dict]):
    """
    æ‰“å°æ§åˆ¶å°ç»“æœï¼Œå¹¶ä¿å­˜åˆ°æœ¬åœ°æ–‡ä»¶ï¼ˆUTF-8ç¼–ç é¿å…ä¹±ç ï¼‰
    """
    if not speed_results:
        print("âŒ  æ— æµ‹é€Ÿç»“æœå¯å±•ç¤º")
        return

    # æ•´ç†æ§åˆ¶å°è¾“å‡ºå†…å®¹
    print("\n" + "="*120)
    print("ğŸ“Š  æµåª’ä½“é“¾æ¥æµ‹é€Ÿç»“æœæ±‡æ€»ï¼ˆæŒ‰ä¸‹è½½é€Ÿåº¦ä»å¿«åˆ°æ…¢æ’åºï¼‰")
    print("="*120)
    print(f"{'åºå·':<4} {'å¯ç”¨çŠ¶æ€':<8} {'å»¶è¿Ÿ(ms)':<12} {'ä¸‹è½½é€Ÿåº¦(Mbps)':<18} {'é“¾æ¥ç®€è¦ä¿¡æ¯'}")
    print("-"*120)

    # æ•´ç†æ–‡ä»¶ä¿å­˜å†…å®¹
    save_content = [
        "æµåª’ä½“é“¾æ¥æµ‹é€Ÿç»“æœæ±‡æ€»",
        f"æµ‹é€Ÿæ—¶é—´ï¼š{time.strftime('%Y-%m-%d %H:%M:%S', time.localtime())}",
        f"é…ç½®å‚æ•°ï¼šä¸‹è½½æµ‹è¯•å¤§å°={DOWNLOAD_TEST_SIZE/(1024*1024)}MBï¼Œè¶…æ—¶æ—¶é—´={TIMEOUT}ç§’",
        "="*120,
        f"{'åºå·':<4} {'å¯ç”¨çŠ¶æ€':<8} {'å»¶è¿Ÿ(ms)':<12} {'ä¸‹è½½é€Ÿåº¦(Mbps)':<18} {'å®Œæ•´é“¾æ¥'} | é”™è¯¯ä¿¡æ¯",
        "-"*120
    ]

    # éå†ç»“æœå¡«å……å†…å®¹
    for idx, result in enumerate(speed_results, 1):
        available_status = "âœ… å¯ç”¨" if result["is_available"] else "âŒ ä¸å¯ç”¨"
        delay = result["response_delay_ms"]
        download_speed = result["download_speed_mbps"]
        link = result["link"]
        error_msg = result["error_msg"]
        link_brief = link[:60] + "..." if len(link) > 60 else link

        # æ‰“å°åˆ°æ§åˆ¶å°
        print(f"{idx:<4} {available_status:<8} {delay:<12} {download_speed:<18} {link_brief}")

        # æ·»åŠ åˆ°ä¿å­˜å†…å®¹
        save_line = f"{idx:<4} {available_status:<8} {delay:<12} {download_speed:<18} {link} | {error_msg}"
        save_content.append(save_line)

    # ä¿å­˜åˆ°æœ¬åœ°æ–‡ä»¶
    if SAVE_RESULT:
        try:
            # è‡ªåŠ¨åˆ›å»ºæ–‡ä»¶å¤¹ï¼ˆè‹¥ä¸å­˜åœ¨ï¼‰
            save_folder = os.path.dirname(RESULT_SAVE_PATH)
            if save_folder and not os.path.exists(save_folder):
                os.makedirs(save_folder)
            
            with open(RESULT_SAVE_PATH, "w", encoding="utf-8") as f:
                f.write("\n".join(save_content))
            
            print(f"\nğŸ‰  æµ‹é€Ÿç»“æœå·²ä¿å­˜åˆ°ï¼š{os.path.abspath(RESULT_SAVE_PATH)}")
        except Exception as e:
            print(f"\nâŒ  ä¿å­˜ç»“æœå¤±è´¥ï¼Œé”™è¯¯ä¿¡æ¯ï¼š{str(e)}")

# ===================== ä¸»ç¨‹åºå…¥å£ï¼ˆç›´æ¥é…ç½®ç½‘ç»œURLå³å¯è¿è¡Œï¼‰ =====================
if __name__ == "__main__":
    # é…ç½®éœ€è¦è§£æçš„ç½‘ç»œURLåˆ—è¡¨ï¼ˆå¯æ·»åŠ å¤šä¸ªï¼Œæ”¯æŒGitHub RAWã€å…¬å…±IPTVåˆ—è¡¨ç­‰ï¼‰
    TARGET_NETWORK_URLS = [
        # æ ¸å¿ƒæµ‹è¯•ç›®æ ‡ï¼šLei9008/IPTV çš„ movie.txt
        "https://raw.githubusercontent.com/Lei9008/IPTV/main/input/source/movie.txt",
        # å¯é€‰ï¼šæ·»åŠ å…¶ä»–IPTVåˆ—è¡¨URL
        # "https://example.com/iptv/playlist.m3u8"
    ]

    # æ­¥éª¤1ï¼šæ‰¹é‡æå–é“¾æ¥å¹¶æµ‹é€Ÿ
    final_test_results = batch_test_stream_links(TARGET_NETWORK_URLS)

    # æ­¥éª¤2ï¼šæ‰“å°å¹¶ä¿å­˜ç»“æœ
    print_and_save_speed_results(final_test_results)
